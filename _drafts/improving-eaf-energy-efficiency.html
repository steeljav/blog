---
layout: post
title: Improving EAF Energy Efficiency
date:
type: post
parent_id: '0'
published: false
password: ''
status: private
categories:
- steeltech
tags:
- oldblog
---
<p><!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"><br />
<html><body></p>
<p>I have been developing and writing quite a bit on various Electric Arc Furnace (EAF) electrical topics. The goal has been to post one write-up per month. I am currently developing another write-up, but it may take a few more days. In the meantime I decided to do something less formal and make a few comments about something closer to the production side of the world with a goal of pointing out how operations has the power to absolutely destroy the efficiency of your highly tuned, highly efficient, state-of-the-art EAF steelmaking process.</p>
<p>One of the main responsibilities I had in a previous position was to improve the energy efficiency of the companies EAFs. I traveled to most of the companies facilities in North America in an effort to accomplish this task. After almost 4 years of travelling and interacting with operators, melters, and managers I started to realize that all of my efforts to improve process performance through EAF modeling and control improvements would not matter if the person operating the EAF did not bother to turn it off when they were supposed to.</p>
<p>One of the parameters that I started to really pay attention to was tapping temperatures. Tapping temperature (tap temp.) is the final temperature of the steel when it is transferred from the EAF into a ladle. I found that typically very little effort (if any) is made to control this parameter. Variances of 20 degrees (or more) above what is necessary are fairly common. To be fair, sometimes there are reasons to heat the steel more than the target. However, in a controlled process occasional exceptions should not cause a noticeable increase in the mean.</p>
<p>I wanted to develop some rules of thumb for heating and cooling rates during refine and the impact in terms of energy efficiency that overheating the steel and delays during refine could have. I did not have the time to develop experiments to measure heating and cooling rates, however I did have a lot of very experienced people to discuss this with. I spoke with many melt shop supervisors (AKA melters) and operators to gauge their estimates on these parameters. I came up with the following: </p>
<ul>
<li>Believe it or not ..... a reasonable average heating rate during refine/heating is approximately 10F/Minute. I felt like this value was way to convenient, but after checking into it I found that it is approximately correct.</li>
<li>EAF steelmakers measure electrical energy efficiency in terms of KWH/Billet Ton. A reasonable efficiency estimate in terms of power on time is between 9 and 10 KWH/Billet Ton per minute of additional power on time.</li>
<li>By combining these first two estimates, it is possible to arrive at an approximate decrease in electrical efficiency of around 10 KWH/Billet Ton for each additional 10 degrees Fahrenheit.</li>
<li>Additionally each 10 degrees Fahrenheit results in approximately one minute of production time. This may seem insignificant, but added over the course of a year (or more), it is significant.</li>
<li>A cooling rate of approximately 5F/Minute of power off time during refine is a reasonable estimate. Keep this in mind when evaluating whether or not to use power demand management. It may not save as much money as it appears to.</li>
</ul>
<p>To put the estimates into perspective, assume that a facility has an EAF with a target tapping temperature of 3000F (fairly typical). If the operators consistently tap at 3010F instead, the facility would be approximately 10 KWH/Billet Ton less efficient. Assuming a 500,000 ton/year facility (fairly typical for the USA) this equates into an additional 5,000,000 KWH. Assuming a KWH cost of around $0.07 gives a cost of $350,000/Year for tapping just a little too hot.</p>
<p>To put the time penalty into perspective, assume a 90 Ton heat size and 60 minute production time per heat (fairly typical for the USA). Assuming 2 shutdown weeks per year and one 8 hour maintenance day per week you can calculate a time loss of approximately 7800 minutes per year. This equates into a loss of 130 heats for our hypothetical facility. The cost of this depends on the final product, market conditions etc. Lets assume approximately $350/Ton (the low end), this results in an annual loss of approximately $50,000 for tapping just a little too hot.</p>
<p>Combining the two loss estimates results in a total of $400,000/Year. Not earth shattering, but a significant amount of capital that could have been employed on something useful. The actual loss would be something higher than this figure because other consumable losses (electrode, refractory, etc) have not been accounted for.</p>
<p>If I were asked for ideas on increasing EAF energy efficiency, knowing nothing about the facility or its specific issues, my advice would be to start by taking a look at the tapping temperature. If it is not being controlled then it is a great place to start energy efficiency improvements. Keep things simple, make statistical control charts and track the values. Post the control charts someplace very visible for the operators to see. If possible tie incentive pay to achieving the target. If this parameter is not under control, or exhibits wide variance then the energy efficiency of the EAF will do the same.</p>
<p>I was basically laughed at for suggesting this to a facility once. They consistently tapped much hotter than what was necessary and it was killing their efficiency. After that I realized that there was not much more I could do to help them. They wanted to improve, but only if they did not have to make any changes. I have no doubt that if I visited that facility today nothing has changed.</p>
<p></body></html></p>
